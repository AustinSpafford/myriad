// We must identify the kernel (entry-point) functions.
#pragma kernel kernel_build_unsorted_voxel_particle_pairs
#pragma kernel kernel_advance_sort_of_voxel_particle_pairs
#pragma kernel kernel_build_spatialization_voxels

#include "spatializer_shader_types.cginc"

#define k_max_positive_integer (int)((uint)-1 >> 1)

uniform uint u_particle_count;

uniform uint u_voxel_count_per_axis;
uniform float u_voxel_size;
uniform uint u_total_voxel_count;

uniform StructuredBuffer<s_particle_position> u_particle_positions;

uniform StructuredBuffer<s_voxel_particle_pair> u_readable_sorted_voxel_particle_pairs;
uniform RWStructuredBuffer<s_voxel_particle_pair> u_out_next_sorted_voxel_particle_pairs;

uniform RWStructuredBuffer<s_spatialization_voxel> u_out_spatialization_voxels;
uniform RWStructuredBuffer<s_neighborhood> u_out_neighborhoods;

uniform uint u_sort_comparison_group_sublist_size_power; // comparison_group_sublist_size = 2^power
uniform uint u_sort_comparison_distance; // distance = 2^(comparison_group_sublist_size_power - 1)
uniform uint u_sort_direction_alternation_sublist_size_power; // direction_alternation_sublist_size = 2^power

uint3 wrap_voxel_coord(
	int3 unbounded_voxel_coord)
{
	// Which wrapping of the voxel-grid are we in?
	int3 macro_voxel_coordinate = (unbounded_voxel_coord / u_voxel_count_per_axis);

	// Determine our position within the macro-voxel. 
	// Note that this is different than using truncation, because we want -1 and 1 to map to
	// different values (to avoid excessive collisions around the origin).
	uint3 wrapped_voxel_coord = (
		unbounded_voxel_coord - 
		(macro_voxel_coordinate * u_voxel_count_per_axis));

	return wrapped_voxel_coord;
}

uint get_voxel_index_from_voxel_coord(
	uint3 wrapped_voxel_coord)
{
	return (
		wrapped_voxel_coord.x +
		(wrapped_voxel_coord.y * u_voxel_count_per_axis) +
		(wrapped_voxel_coord.z * (u_voxel_count_per_axis * u_voxel_count_per_axis)));
}

[numthreads(128, 1, 1)]
void kernel_build_unsorted_voxel_particle_pairs(
	uint3 thread_id : SV_DispatchThreadID)
{
	uint particle_index = thread_id.x;
	
	// In the last thread group, if it's safe to access the buffers.
	if (particle_index < u_particle_count)
	{
		float3 position_in_voxel_space = (u_particle_positions[particle_index].position / u_voxel_size);

		int3 unbounded_voxel_coord = (int3)floor(position_in_voxel_space);

		// Which wrapping of the voxel-grid are we in?
		int3 macro_voxel_coordinate = (unbounded_voxel_coord / u_voxel_count_per_axis);

		// Determine our position within the meta-voxel. Note that this is different than using truncation,
		// because we want -1 and 1 to map to different values (to avoid excessive collisions around the origin).
		uint3 wrapped_voxel_coord = (
			unbounded_voxel_coord - 
			(macro_voxel_coordinate * u_voxel_count_per_axis));

		float3 position_fraction = (position_in_voxel_space - unbounded_voxel_coord);

		// Create an offset that's (-1, -1, -1) in the lowest-corner of each voxel, and (0, 0, 0) in
		// the highest-corner. This allows us to specify each particle's
		// neighborhood (which is a group of 8 adjacent voxels) by the coordinate of the lowest-corner voxel.
		int3 offset_from_particle_voxel_to_neighborhood_min_voxel_coord = 
			(int3)floor(position_fraction - 0.5f);

		// Output results.
		{
			// NOTE: We're providing the initial particle-sorted pairings, which will
			// soon become voxel-sorted so they're spatially-relevent.

			u_out_next_sorted_voxel_particle_pairs[particle_index].voxel_index = 
				get_voxel_index_from_voxel_coord(wrapped_voxel_coord);

			u_out_next_sorted_voxel_particle_pairs[particle_index].particle_index = 
				particle_index;

			u_out_neighborhoods[particle_index].neighborhood_min_voxel_coord = 
				wrap_voxel_coord(
					wrapped_voxel_coord +
					offset_from_particle_voxel_to_neighborhood_min_voxel_coord);
		}
	}
	else
	{
		// This voxel-particle pair needs to replaced with a dummy value that the sort
		// algorithm (which only operates on powers of two) will place at the end of the buffer.
		// That will keep all the sort-waste particles from mucking up the later spatialization stages.
		// NOTE: We're assuming the threadGroup is already a small power of two for this step, so there shouldn't be any excess-threads.
		u_out_next_sorted_voxel_particle_pairs[particle_index].voxel_index = k_max_positive_integer;
		u_out_next_sorted_voxel_particle_pairs[particle_index].particle_index = k_max_positive_integer;
		u_out_neighborhoods[particle_index].neighborhood_min_voxel_coord = k_max_positive_integer;
	}
}

[numthreads(128, 1, 1)]
void kernel_advance_sort_of_voxel_particle_pairs(
	uint3 thread_id : SV_DispatchThreadID)
{
	// This function implements a single-step of: https://en.wikipedia.org/wiki/Bitonic_sorter
	// NOTE: We're assuming the threadGroup is already a small power of two for this step, so there shouldn't be any excess-threads.

	uint self_index = thread_id.x;

	bool self_is_first_half_of_comparison = 
		(((self_index >> (u_sort_comparison_group_sublist_size_power - 1)) & 1) == 0);

	bool sublist_is_ascending = (((self_index >> u_sort_direction_alternation_sublist_size_power) & 1) == 0);

	uint partner_index = (uint)(
		self_index + 
		(self_is_first_half_of_comparison ? (int)u_sort_comparison_distance : (-1 * (int)u_sort_comparison_distance)));

	bool self_desires_lower_key = (sublist_is_ascending == self_is_first_half_of_comparison);

	int self_to_partner_sort_key_difference = (
		u_readable_sorted_voxel_particle_pairs[partner_index].voxel_index -
		u_readable_sorted_voxel_particle_pairs[self_index].voxel_index);

	bool self_has_desired_key = (
		(self_to_partner_sort_key_difference == 0) ||
		(self_desires_lower_key == (self_to_partner_sort_key_difference > 0)));

	uint desired_value_index = (self_has_desired_key ? self_index : partner_index);

	u_out_next_sorted_voxel_particle_pairs[self_index] = 
		u_readable_sorted_voxel_particle_pairs[desired_value_index];
}

[numthreads(128, 1, 1)]
void kernel_build_spatialization_voxels(
	uint3 thread_id : SV_DispatchThreadID)
{
	uint voxel_index = thread_id.x;

	// In the last thread group, if it's safe to access the buffers.
	if (voxel_index < u_total_voxel_count)
	{
		uint candidates_first_index = 0;
		uint candidates_term_index = u_particle_count; // NOTE: By using "term" instead of "last", "first will correctly end up out-of-bounds when the entire array is smaller than the target value.

		while (candidates_first_index != candidates_term_index)
		{
			uint middle_index = ((candidates_first_index + candidates_term_index) >> 1);

			bool target_is_in_lower_half =
				(voxel_index <= u_readable_sorted_voxel_particle_pairs[middle_index].voxel_index);

			// Ensure that we're always making progress, even in the last few steps
			// where the fact that middle_index is rounded down means first_index==middle_index.
			uint safe_moved_first_index = max(middle_index, (candidates_first_index + 1));
			
			candidates_first_index = (target_is_in_lower_half ? candidates_first_index : safe_moved_first_index);
			candidates_term_index = (target_is_in_lower_half ? middle_index : candidates_term_index);
		}

		u_out_spatialization_voxels[voxel_index].first_voxel_particle_pair_index = candidates_first_index;
	}
}
